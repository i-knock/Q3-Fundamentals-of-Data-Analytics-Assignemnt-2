{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Notes\n",
    "- Use BeautifulSoup (4) for html scraping\n",
    "  - https://realpython.com/python-web-scraping-practical-introduction/\n",
    "  - https://realpython.com/beautiful-soup-web-scraper-python/#step-1-inspect-your-data-source\n",
    "  - `.prettify()` can be useful to look at the source code\n",
    "- To join absolute and reltative pages: use module `urlparse`\n",
    "  - `urlparse.urljoin(url1, url2)`\n",
    "- To actually *get* the page, you should use the module `requests`\n",
    "  - `page = requests.get(URL)`\n",
    "  - `soup = BeautifulSoup(page.content , \"html.parser\"`\n",
    "- Process:\n",
    "  - How ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Deadline**: 1st April 2022 18:00\n",
    "-  Questions:\n",
    "    1. Are there couples among the employees. If so, who? Are they still together?\n",
    "       1. Look if they go on holidays together\n",
    "       2. Look if they changed surnames\n",
    "       3. Look if they had children\n",
    "    2. Did any of the employees have a child? If so, who?\n",
    "       1. 9+ month \"break\"\n",
    "       2. If the mother leaves for 9+ months, then the father might also take a leave\n",
    "       3. They might decrease how much they work (frequency of publish)\n",
    "    3. If you would be looking to work for Tabularazor Inc., how many holidays can you expect to get per year?\n",
    "       1. Look at all periods that are larger than \"working but not publishing\", but shorter than \"we're having a baby\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 14\n",
    "- Antonio Sanchez Martin - ''5245834''\n",
    "- Felix Unger - ''5673631''\n",
    "- Jeroen van Paassen - ''4720970''\n",
    "- Yunus Emre Torlak - ''5597668''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning:\n",
    "\n",
    "1. Put the code in visual studio and visualize the basic dataset\n",
    "2. Figure out how to use the dataset to do the plots\n",
    "3. Make the plots (draw conslusions?)\n",
    "4. How do we use the plots to answer the questions?\n",
    "5. Structure the report, divide the questions and explain relevant plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "First, we plot some diagrams to visualize the dataset that we have. The plots that we will make are:\n",
    "- histogram with number of employees on x-axis and amount of work posted on the y-axis (to see frequency of work posted)\n",
    "- a plot with the productivity of a random employee over time\n",
    "- histogram with amount of employees on the x-axis and the frequency of reoccuring last name on the y-axis\n",
    "- the productivity of employees sharing the same name over time? (covariance)\n",
    "- scatterplot with years on x-axis and time on y-axis, to see the behaviour of posting articles over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Some important things that we need to take into account when using the dataset:\n",
    "- there could be people with the exact same name\n",
    "- an absence of over 16 weeks could be considered as pregnancy (6 for pregnancy and 10 after giving birth)\n",
    "- for men that is at minimum 1 week (->can we link ''holidays'' to pregnancy of the partner?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering the questions\n",
    "\n",
    "After making the plots, we focus on answering the questions, which we will do with the help of the plots:\n",
    "a. Are there couples among the employees. If so, who? Are they still together?\n",
    "- same/change of last name, covariance in days of, corresponding time of absence (partner of pregnant employee is absent for a short while during the 16+ week absence of the female partner)\n",
    "b. Did any of the employees have a child? If so, who?\n",
    "- absence for 16+ weeks, decrease in productivity, change in posting behaviour\n",
    "c. If you would be looking to work for Tabularazor Inc., how many holidays can you expect to get per\n",
    "year?\n",
    "- look at average days off/productivity, account for pregnancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the table\n",
    "- Row -> Article entry on the website\n",
    "- Columns -> \n",
    "  - Name\n",
    "  - Date\n",
    "  - Time\n",
    "- Idea: Use `datetime` for storing the date data in a flexible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Articles\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   All articles\n",
      "  </h1>\n",
      "  <br/>\n",
      "  <br/>\n",
      "  <h2>\n",
      "   Articles year 2012\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2012.html\">\n",
      "    Articles in 2012\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2013\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2013.html\">\n",
      "    Articles in 2013\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2014\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2014.html\">\n",
      "    Articles in 2014\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2015\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2015.html\">\n",
      "    Articles in 2015\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2016\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2016.html\">\n",
      "    Articles in 2016\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2017\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2017.html\">\n",
      "    Articles in 2017\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2018\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2018.html\">\n",
      "    Articles in 2018\n",
      "   </a>\n",
      "  </div>\n",
      "  <h2>\n",
      "   Articles year 2019\n",
      "  </h2>\n",
      "  <br/>\n",
      "  <div class=\"yearlink\">\n",
      "   <a href=\"./2019.html\">\n",
      "    Articles in 2019\n",
      "   </a>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "\n",
    "get_soup = lambda link: bs.BeautifulSoup(requests.get(link).content)\n",
    "soup = get_soup(website)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://jdestefani.github.io/SEN163A-TabularRazorArchives/2012.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2013.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2014.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2015.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2016.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2017.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2018.html', 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/2019.html']\n"
     ]
    }
   ],
   "source": [
    "# Get all links on site\n",
    "# Checked: Works as expected\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_links(to_scrape = 'https://jdestefani.github.io/SEN163A-TabularRazorArchives/'):\n",
    "    soup = get_soup(to_scrape)\n",
    "    links = soup.find_all('a', href=True)\n",
    "    if links is False:\n",
    "        return [] # remember that empty arrays are \"false\" in python\n",
    "    links = [urljoin(to_scrape, link['href']) for link in links]\n",
    "    return links\n",
    "\n",
    "print(get_links(to_scrape=website))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start getting url\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, website:str):\n",
    "        self.scraped_data = list() # create a list to append all website inforation\n",
    "        self.scrape(website)\n",
    "        fields = ['link','author', 'date', 'time'] # columns of table\n",
    "        self.scraped_data= pd.DataFrame(self.scraped_data, columns = fields) # export as a dataframe\n",
    "\n",
    "    def scrape(self, website): \n",
    "        all_links = get_links(website)\n",
    "        if all_links:\n",
    "            # Keep on searching\n",
    "            for link in all_links:\n",
    "                ## print(f\"Searching: {link}\")\n",
    "                self.scrape(link)\n",
    "        else:\n",
    "            # Get the data (i.e. base case)\n",
    "            ## print(\"Reached the bottom\")\n",
    "            soup = get_soup(website) # get the soup object for extracting info\n",
    "            web_info= list()\n",
    "            web_info.append(website)\n",
    "            web_info.append(soup.find_all('div', class_='author')[0].text)\n",
    "            web_info.append(soup.find_all('div', class_='date')[0].text)\n",
    "            web_info.append(soup.find_all('div', class_='time')[0].text)\n",
    "            self.scraped_data.append(web_info) # append to object list\n",
    "            \n",
    "# output = Scraper(website)\n",
    "output = Scraper('https://jdestefani.github.io/SEN163A-TabularRazorArchives/2012-1.html').scraped_data\n",
    "\n",
    "# Save the data so that it does not have to be scraped every time\n",
    "output.to_csv('scraped_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://jdestefani.github.io/SEN163A-TabularRa...</td>\n",
       "      <td>Jaye Shimek</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>15:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link       author        date  \\\n",
       "0  https://jdestefani.github.io/SEN163A-TabularRa...  Jaye Shimek  2012-01-01   \n",
       "\n",
       "    time  \n",
       "0  15:17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the scraped web data\n",
    "import pandas as pd\n",
    "web_data = pd.read_csv('scraped_data.csv')\n",
    "web_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n",
    "Axis Formatting:\n",
    "-y-axis Timestamp with 0-24 h \n",
    "-x-axis date from 2012 to 2020\n",
    "-different colors each employee\n",
    "\n",
    "Analysis: \n",
    "-changes in publishing time and frequency? \n",
    "-correlation to children or marriage? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee Histogram\n",
    "Axis Formatting: histogram with number of employees on x-axis and amount of work posted on the y-axis (to see frequency of work posted), \n",
    "note: if productivity is double the average, it could be the case that there are 2 employees with the exact same name\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Name Histogram\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
